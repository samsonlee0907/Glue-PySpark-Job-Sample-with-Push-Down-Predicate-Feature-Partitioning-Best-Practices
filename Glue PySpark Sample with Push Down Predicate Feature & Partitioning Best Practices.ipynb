{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glue PySpark Job Sample with Push Down Predicate Feature & Partitioning Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provide examples on how using Push Down Predicate along with partitioned data set can reduce the time & resources required to process the data when using AWS Glue as a serverless PySpark executor. To run this sample notebook, you may either use Glue Development Endpoint along with a SageMaker notebook, or follow the blog post [here](https://aws.amazon.com/blogs/big-data/developing-aws-glue-etl-jobs-locally-using-a-container/) to run a local Jupyter notebook pre-configured with Glue libraries. To benchmark the results, as of the time running the jobs below, a container with 2GB memory available is being used.\n",
    "\n",
    "The push down predicate feature is being used to test against the same set of data but being partitioned with two different approaches:\n",
    "1. Date\n",
    "2. Year/Month/Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T16:47:53.846527Z",
     "start_time": "2021-08-30T16:47:32.032315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>10</td><td>None</td><td>pyspark</td><td>idle</td><td></td><td></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.transforms import *\n",
    "\n",
    "glueContext = GlueContext(SparkContext.getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T00:00:40.650531Z",
     "start_time": "2021-08-31T00:00:40.522142Z"
    }
   },
   "source": [
    "## 1. Date-partitioned Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the schema of the date-partitioned data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T16:48:34.774485Z",
     "start_time": "2021-08-30T16:48:33.914710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|                bsid|   bigint|   null|\n",
      "|               dtsid|   bigint|   null|\n",
      "|                msid|   bigint|   null|\n",
      "|                 msv|   bigint|   null|\n",
      "|                   t|   bigint|   null|\n",
      "|                   c|   bigint|   null|\n",
      "|                   b|   bigint|   null|\n",
      "|           file_date|   string|   null|\n",
      "|          reading_dt|   string|   null|\n",
      "|        reading_date|   string|   null|\n",
      "|# Partition Infor...|         |       |\n",
      "|          # col_name|data_type|comment|\n",
      "|        reading_date|   string|   null|\n",
      "+--------------------+---------+-------+"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe devtest.date_partitioned_data\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to get the full data set first to inspect the details of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T16:51:13.003858Z",
     "start_time": "2021-08-30T16:48:34.778106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_data = glueContext.create_dynamic_frame.from_catalog(database = \"devtest\", table_name = \"date_partitioned_data\",\n",
    "                                                                    transformation_ctx = \"datasource_catalog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T00:10:30.973380Z",
     "start_time": "2021-08-31T00:10:30.118597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------+-------+---+---+---+----------+--------------------+------------+----+-----+---+\n",
      "|    bsid|dtsid|  msid|    msv|  t|  c|  b| file_date|          reading_dt|reading_date|year|month|day|\n",
      "+--------+-----+------+-------+---+---+---+----------+--------------------+------------+----+-----+---+\n",
      "|90020195|   13|   576|   1905|  0|  0|  0|2019-06-01|2019-05-31 13:40:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|   20|   794|   1136|  0|  0|  1|2019-06-03|2019-06-02 17:02:...|  2019-06-02|2019|    6|  2|\n",
      "|90020195|    3|   105|   1206|  0|  0|  0|2019-06-01|2019-05-31 02:27:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|    8|   282|      0|  0|  0|  0|2019-06-02|2000-01-01 00:00:...|  2000-01-01|2000|    1|  1|\n",
      "|82000086|    0|802203|5862267|  0|  0|  0|2019-06-03|2019-06-02 13:00:...|  2019-06-02|2019|    6|  2|\n",
      "|90020195|    2|    47|   2457|  0|  0|  0|2019-06-02|2019-06-01 01:25:...|  2019-06-01|2019|    6|  1|\n",
      "|82000086|    0|802203|5863484|  0|  0|  0|2019-06-04|2019-06-03 16:00:...|  2019-06-03|2019|    6|  3|\n",
      "|90020195|   18|   738|   2369|  0|  0|  0|2019-06-01|2019-05-31 17:07:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|    8|   295|    619|  0|  0|  1|2019-06-01|2019-05-31 04:28:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|    6|   234|   1912|  0|  0|  1|2019-06-01|2019-05-31 00:07:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|   14|   540|      0|  0|  0|  0|2019-06-04|2000-01-01 00:00:...|  2000-01-01|2000|    1|  1|\n",
      "|90020195|   13|   553|   5489|  0|  0|  1|2019-06-04|2019-06-03 06:47:...|  2019-06-03|2019|    6|  3|\n",
      "|90020195|    1|    69|      0|  0|  0|  0|2019-06-01|2000-01-01 00:00:...|  2000-01-01|2000|    1|  1|\n",
      "|90020195|    5|   197|   1248|  0|  0|  0|2019-06-03|2019-06-02 02:22:...|  2019-06-02|2019|    6|  2|\n",
      "|82000086|    0|802203|5862267|  0|  0|  0|2019-06-03|2019-06-02 11:45:...|  2019-06-02|2019|    6|  2|\n",
      "|90020195|    1|    67|   1579|  0|  0|  0|2019-06-03|2019-06-02 01:49:...|  2019-06-02|2019|    6|  2|\n",
      "|90020195|   19|   787|    405|  0|  0|  1|2019-06-04|2019-06-02 16:32:...|  2019-06-02|2019|    6|  2|\n",
      "|90020195|   17|   741|      0|  0|  0|  0|2019-06-04|2000-01-01 00:00:...|  2000-01-01|2000|    1|  1|\n",
      "|90020316|    2|    27|   1550|  0|  0|  0|2019-06-02|2019-06-01 00:54:...|  2019-06-01|2019|    6|  1|\n",
      "|90020195|   20|   783|    741|  0|  0|  0|2019-06-03|2019-06-02 18:28:...|  2019-06-02|2019|    6|  2|\n",
      "+--------+-----+------+-------+---+---+---+----------+--------------------+------------+----+-----+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "Total records:  4516"
     ]
    }
   ],
   "source": [
    "full_data.toDF().show()\n",
    "print('Total records: ', full_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found that getting the full set of data requires more than 2 minutes, and to convert the data from DynamicFrame to DataFrame would take another 3-5 minutes.\n",
    "\n",
    "Next trying to leverage \"push_down_predicate\" to limit the Glue job to return 1 month (2019/5) of data using the between method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T16:55:50.899444Z",
     "start_time": "2021-08-30T16:55:18.973888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exact_month_data = glueContext.create_dynamic_frame.from_catalog(database = \"devtest\", table_name = \"date_partitioned_data\", \n",
    "                                                                    push_down_predicate = \"(reading_date between '2019-05-01'and '2019-05-31')\", transformation_ctx = \"datasource_catalog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T16:56:30.473717Z",
     "start_time": "2021-08-30T16:55:50.909860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------+-------+---+---+---+----------+--------------------+------------+\n",
      "|    bsid|dtsid|  msid|    msv|  t|  c|  b| file_date|          reading_dt|reading_date|\n",
      "+--------+-----+------+-------+---+---+---+----------+--------------------+------------+\n",
      "|90020195|    8|   294|   2466|  0|  0|  1|2019-06-01|2019-05-31 04:28:...|  2019-05-31|\n",
      "|90020195|    1|    64|   2133|  0|  0|  0|2019-06-01|2019-05-31 23:29:...|  2019-05-31|\n",
      "|90020195|    5|   201|   1173|  0|  0|  0|2019-06-01|2019-05-31 01:32:...|  2019-05-31|\n",
      "|90020195|    4|   134|   1640|  0|  0|  0|2019-06-01|2019-05-31 23:04:...|  2019-05-31|\n",
      "|90020195|   15|   616|   2201|  0|  0|  1|2019-06-01|2019-05-31 12:16:...|  2019-05-31|\n",
      "|82000086|    0|802203|5860144|  0|  0|  0|2019-06-01|2019-05-31 20:00:...|  2019-05-31|\n",
      "|90020195|    9|   395|   4121|  0|  0|  1|2019-06-01|2019-05-31 08:19:...|  2019-05-31|\n",
      "|90020195|   24|   994|   3151|  0|  0|  1|2019-06-01|2019-05-31 23:28:...|  2019-05-31|\n",
      "|90020195|    3|   144|    813|  0|  0|  0|2019-06-01|2019-05-31 03:25:...|  2019-05-31|\n",
      "|90020195|   23|   979|   3741|  0|  0|  1|2019-06-01|2019-05-31 19:37:...|  2019-05-31|\n",
      "|90020195|    5|   192|   1869|  0|  0|  0|2019-06-01|2019-05-31 12:04:...|  2019-05-31|\n",
      "|90020195|   14|   535|   2241|  0|  0|  1|2019-06-01|2019-05-31 10:20:...|  2019-05-31|\n",
      "|90020195|   10|   359|   1658|  0|  0|  1|2019-06-01|2019-05-31 05:28:...|  2019-05-31|\n",
      "|90020195|   22|   924|   1287|  0|  0|  1|2019-06-01|2019-05-31 20:04:...|  2019-05-31|\n",
      "|90020195|   24|   982|   1396|  0|  0|  1|2019-06-01|2019-05-31 21:04:...|  2019-05-31|\n",
      "|90020195|    3|   149|   2841|  0|  0|  0|2019-06-01|2019-05-31 01:59:...|  2019-05-31|\n",
      "|90020195|    9|   427|   1590|  0|  0|  1|2019-06-01|2019-05-31 12:09:...|  2019-05-31|\n",
      "|82000086|    0|802203|5858944|  0|  0|  0|2019-06-01|2019-05-31 11:30:...|  2019-05-31|\n",
      "|90020195|   14|   543|   1252|  0|  0|  0|2019-06-01|2019-05-31 12:44:...|  2019-05-31|\n",
      "|90020195|    4|   156|   2348|  0|  0|  0|2019-06-01|2019-05-31 22:06:...|  2019-05-31|\n",
      "+--------+-----+------+-------+---+---+---+----------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Total records:  962"
     ]
    }
   ],
   "source": [
    "exact_month_data.toDF().show()\n",
    "print('Total records: ', exact_month_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time required to get the data reduced from around 150 seconds to around 30 seconds now.\n",
    "\n",
    "Then let's further try pushing down the predicate to an exact date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T16:56:35.814979Z",
     "start_time": "2021-08-30T16:56:30.478050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exact_date_data = glueContext.create_dynamic_frame.from_catalog(database = \"devtest\", table_name = \"date_partitioned_data\",\n",
    "                                                                push_down_predicate = \"(reading_date == '2019-05-29')\", transformation_ctx = \"datasource_catalog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T16:56:39.231872Z",
     "start_time": "2021-08-30T16:56:35.820076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----+----+---+---+---+----------+--------------------+------------+\n",
      "|    bsid|dtsid|msid| msv|  t|  c|  b| file_date|          reading_dt|reading_date|\n",
      "+--------+-----+----+----+---+---+---+----------+--------------------+------------+\n",
      "|90020195|   24| 962|  25|  0|  0|  1|2019-06-03|2019-05-29 19:45:...|  2019-05-29|\n",
      "|90020195|   16| 674|2800|  0|  0|  0|2019-06-03|2019-05-29 12:25:...|  2019-05-29|\n",
      "|90020195|   17| 705|1070|  0|  0|  0|2019-06-02|2019-05-29 16:45:...|  2019-05-29|\n",
      "|90020195|   17| 705|1070|  0|  0|  0|2019-06-01|2019-05-29 16:45:...|  2019-05-29|\n",
      "|90020195|   17| 705|1070|  0|  0|  0|2019-06-04|2019-05-29 16:45:...|  2019-05-29|\n",
      "|90020195|   24| 962|  25|  0|  0|  1|2019-06-04|2019-05-29 19:45:...|  2019-05-29|\n",
      "|90020195|   17| 705|1070|  0|  0|  0|2019-06-03|2019-05-29 16:45:...|  2019-05-29|\n",
      "|90020195|   16| 674|2800|  0|  0|  0|2019-06-04|2019-05-29 12:25:...|  2019-05-29|\n",
      "|90020195|    3| 168|4113|  0|  0|  0|2019-06-04|2019-05-29 04:01:...|  2019-05-29|\n",
      "|90020195|    3| 168|4113|  0|  0|  0|2019-06-02|2019-05-29 04:01:...|  2019-05-29|\n",
      "|90020195|    3| 168|4113|  0|  0|  0|2019-06-01|2019-05-29 04:01:...|  2019-05-29|\n",
      "|90020195|   16| 674|2800|  0|  0|  0|2019-06-02|2019-05-29 12:25:...|  2019-05-29|\n",
      "|90020195|   24| 962|  25|  0|  0|  1|2019-06-01|2019-05-29 19:45:...|  2019-05-29|\n",
      "|90020195|    3| 168|4113|  0|  0|  0|2019-06-03|2019-05-29 04:01:...|  2019-05-29|\n",
      "|90020195|    1|   9|2057|  0|  0|  0|2019-06-01|2019-05-29 20:15:...|  2019-05-29|\n",
      "|90020195|   24| 962|  25|  0|  0|  1|2019-06-02|2019-05-29 19:45:...|  2019-05-29|\n",
      "|90020195|   16| 674|2800|  0|  0|  0|2019-06-01|2019-05-29 12:25:...|  2019-05-29|\n",
      "+--------+-----+----+----+---+---+---+----------+--------------------+------------+\n",
      "\n",
      "Total records:  17"
     ]
    }
   ],
   "source": [
    "exact_date_data.toDF().show()\n",
    "print('Total records: ', exact_date_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes just 5-6 seconds to actually get the data from an exact date.\n",
    "\n",
    "Hence a short conclusion here is, without using \"push_down_predicate\", while the data is being partitioned, it may create resource wastage in running the Glue job. It is also important to select the right partition key with reference from how the expected ETL process is going to target a specific range of data by columns / features. As an illustration, we are now going to transform the data to a year/month/day partitioning approach and illustrate how to transfrom the DataFrame with PySpark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Year/Month/Day-partitioned Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are native PySpark functions that can be leveraged for targeting date / timestamp data type, to easily capture the specific date / time values to create new columns.\n",
    "\n",
    "Below illustrated when \"reading_date\" is a timestamp value, we can use **year(\"reading_date\")** to capture the year value, and same for creating the columns for month and day.\n",
    "\n",
    "In case your data did not come in as a date / timestamp data type, you may leverage \"to_date\" / \"to_timestamp\" PySpark functions.\n",
    "\n",
    "For example: **to_timestamp('201905290812', 'yyyyMMddHHmm')**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T00:21:57.761478Z",
     "start_time": "2021-08-31T00:21:56.890956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partitions added:  200"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth\n",
    "\n",
    "repartitioned_full_data = full_data.toDF().withColumn(\"Year\", year(\"reading_date\")).withColumn(\"Month\", month(\"reading_date\")).withColumn(\"Day\", dayofmonth(\"reading_date\"))\n",
    "repartitioned_full_data = repartitioned_full_data.repartition(\"Year\", \"Month\", \"Day\")\n",
    "print('partitions added: ', repartitioned_full_data.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is to write the data back into S3 with a new partitioning approach. In order to write data in partitions with Glue, when writing the DynamicFrame, specify the Partition Keys in \"connection_options\" with format of **\"partitionKeys\":[\"ColumnName\"]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsglue.dynamicframe import DynamicFrame\n",
    "\n",
    "ymd_partitioned_dyf = DynamicFrame.fromDF(repartitioned_full_data, glueContext, \"ymd_partitioned_dyf\")\n",
    "\n",
    "datasink_s3 = glueContext.write_dynamic_frame.from_options(frame = ymd_partitioned_dyf, \n",
    "                                                           connection_type = \"s3\", \n",
    "                                                           connection_options = {\"path\": \"s3://glue-devtest-bucket/ymd_partitioned_data\", \n",
    "                                                                                 \"partitionKeys\":[\"Year\", \"Month\", \"Day\"]}, format = \"parquet\", transformation_ctx = \"datasink_s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now examine the new data set schema. We can see the Partition Information section has changed from using the reading_date as the partition key to year, month and day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T16:56:47.331608Z",
     "start_time": "2021-08-30T16:56:46.017995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|                bsid|   bigint|   null|\n",
      "|               dtsid|   bigint|   null|\n",
      "|                msid|   bigint|   null|\n",
      "|                 msv|   bigint|   null|\n",
      "|                   t|   bigint|   null|\n",
      "|                   c|   bigint|   null|\n",
      "|                   b|   bigint|   null|\n",
      "|           file_date|   string|   null|\n",
      "|          reading_dt|   string|   null|\n",
      "|        reading_date|   string|   null|\n",
      "|                year|   string|   null|\n",
      "|               month|   string|   null|\n",
      "|                 day|   string|   null|\n",
      "|# Partition Infor...|         |       |\n",
      "|          # col_name|data_type|comment|\n",
      "|                year|   string|   null|\n",
      "|               month|   string|   null|\n",
      "|                 day|   string|   null|\n",
      "+--------------------+---------+-------+"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe devtest.ymd_partitioned_data\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick experiment here is to get a month of data out of this newly partitioned data set. Unlike previously using the between method, now we can specific an exact year & month value for the \"push_down_predicate\" parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T17:03:57.580389Z",
     "start_time": "2021-08-30T17:03:28.001594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exact_month_data = glueContext.create_dynamic_frame.from_catalog(database = \"devtest\", table_name = \"ymd_partitioned_data\", \n",
    "                                                                 push_down_predicate = \"(year == '2019'and month == '5')\", transformation_ctx = \"datasource_catalog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite there are additional columns generated due to the new partitioning method, the time required to get the data is slighly faster for a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T17:04:41.196085Z",
     "start_time": "2021-08-30T17:03:57.588021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------+-------+---+---+---+----------+--------------------+------------+----+-----+---+\n",
      "|    bsid|dtsid|  msid|    msv|  t|  c|  b| file_date|          reading_dt|reading_date|year|month|day|\n",
      "+--------+-----+------+-------+---+---+---+----------+--------------------+------------+----+-----+---+\n",
      "|90020195|   11|   464|   1250|  0|  0|  1|2019-06-01|2019-05-31 09:48:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|    9|   409|   3731|  0|  0|  1|2019-06-01|2019-05-31 06:24:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|   13|   579|   3267|  0|  0|  1|2019-06-01|2019-05-31 11:16:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|   13|   560|   2974|  0|  0|  1|2019-06-01|2019-05-31 13:11:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|    4|   142|   3014|  0|  0|  0|2019-06-01|2019-05-31 01:31:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|    8|   340|   3814|  0|  0|  1|2019-06-01|2019-05-31 15:00:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|    7|   291|   1623|  0|  0|  1|2019-06-01|2019-05-31 03:58:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|    3|   129|   3215|  0|  0|  0|2019-06-01|2019-05-31 01:01:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|   20|   782|   2001|  0|  0|  1|2019-06-01|2019-05-31 16:12:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|   18|   743|   4217|  0|  0|  0|2019-06-01|2019-05-31 16:38:...|  2019-05-31|2019|    5| 31|\n",
      "|90020316|    2|    32|    387|  0|  0|  1|2019-06-01|2019-05-18 00:14:...|  2019-05-18|2019|    5| 18|\n",
      "|90020195|    1|    83|   1368|  0|  0|  0|2019-06-02|2019-05-31 23:00:...|  2019-05-31|2019|    5| 31|\n",
      "|82000086|    0|802203|5860090|  0|  0|  0|2019-06-01|2019-05-31 19:30:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|   18|   724|   2325|  0|  0|  1|2019-06-01|2019-05-31 15:41:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|   18|   700|   2806|  0|  0|  1|2019-06-01|2019-05-31 13:17:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|   10|   359|   1658|  0|  0|  1|2019-06-01|2019-05-31 05:28:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|    3|   139|   2946|  0|  0|  0|2019-06-01|2019-05-31 23:03:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|    1|    24|   1782|  0|  0|  0|2019-06-01|2019-05-31 22:03:...|  2019-05-31|2019|    5| 31|\n",
      "|90020195|    6|   199|    744|  0|  0|  0|2019-06-02|2019-05-28 05:06:...|  2019-05-28|2019|    5| 28|\n",
      "|90020195|   17|   712|      0|  0|  0|  1|2019-06-03|2019-05-28 13:56:...|  2019-05-28|2019|    5| 28|\n",
      "+--------+-----+------+-------+---+---+---+----------+--------------------+------------+----+-----+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "Total records:  962"
     ]
    }
   ],
   "source": [
    "exact_month_data.toDF().show()\n",
    "print('Total records: ', exact_month_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While converting the DynamicFrame to DataFrame takes relatively longer here with a few seconds more, mainly because the additional columns are present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Final Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, we will try one more round to compare across 3 approaches to achieve the same results of getting an exact date of data:\n",
    "\n",
    "1. Without using \"push_down_predicate\" but filter the date with DynamicFrame native functions\n",
    "2. Using \"push_down_predicate\" to filter the data returned from Glue\n",
    "3. Using \"push_down_predicate\" on a year/month/day-parttioned data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T00:10:30.103627Z",
     "start_time": "2021-08-31T00:04:34.849603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------+----+--------------------+----+-----+----+---+----------+-----+------------+---+\n",
      "|  b|  t|    bsid| msv|          reading_dt|year|dtsid|msid|  c| file_date|month|reading_date|day|\n",
      "+---+---+--------+----+--------------------+----+-----+----+---+----------+-----+------------+---+\n",
      "|  0|  0|90020195|1070|2019-05-29 16:45:...|2019|   17| 705|  0|2019-06-02|    5|  2019-05-29| 29|\n",
      "|  0|  0|90020195|2800|2019-05-29 12:25:...|2019|   16| 674|  0|2019-06-01|    5|  2019-05-29| 29|\n",
      "|  0|  0|90020195|1070|2019-05-29 16:45:...|2019|   17| 705|  0|2019-06-03|    5|  2019-05-29| 29|\n",
      "|  0|  0|90020195|1070|2019-05-29 16:45:...|2019|   17| 705|  0|2019-06-04|    5|  2019-05-29| 29|\n",
      "|  0|  0|90020195|4113|2019-05-29 04:01:...|2019|    3| 168|  0|2019-06-04|    5|  2019-05-29| 29|\n",
      "|  1|  0|90020195|  25|2019-05-29 19:45:...|2019|   24| 962|  0|2019-06-03|    5|  2019-05-29| 29|\n",
      "|  1|  0|90020195|  25|2019-05-29 19:45:...|2019|   24| 962|  0|2019-06-01|    5|  2019-05-29| 29|\n",
      "|  0|  0|90020195|1070|2019-05-29 16:45:...|2019|   17| 705|  0|2019-06-01|    5|  2019-05-29| 29|\n",
      "|  0|  0|90020195|2800|2019-05-29 12:25:...|2019|   16| 674|  0|2019-06-04|    5|  2019-05-29| 29|\n",
      "|  1|  0|90020195|  25|2019-05-29 19:45:...|2019|   24| 962|  0|2019-06-02|    5|  2019-05-29| 29|\n",
      "|  0|  0|90020195|2057|2019-05-29 20:15:...|2019|    1|   9|  0|2019-06-01|    5|  2019-05-29| 29|\n",
      "|  0|  0|90020195|4113|2019-05-29 04:01:...|2019|    3| 168|  0|2019-06-01|    5|  2019-05-29| 29|\n",
      "|  0|  0|90020195|4113|2019-05-29 04:01:...|2019|    3| 168|  0|2019-06-03|    5|  2019-05-29| 29|\n",
      "|  0|  0|90020195|2800|2019-05-29 12:25:...|2019|   16| 674|  0|2019-06-02|    5|  2019-05-29| 29|\n",
      "|  1|  0|90020195|  25|2019-05-29 19:45:...|2019|   24| 962|  0|2019-06-04|    5|  2019-05-29| 29|\n",
      "|  0|  0|90020195|4113|2019-05-29 04:01:...|2019|    3| 168|  0|2019-06-02|    5|  2019-05-29| 29|\n",
      "|  0|  0|90020195|2800|2019-05-29 12:25:...|2019|   16| 674|  0|2019-06-03|    5|  2019-05-29| 29|\n",
      "+---+---+--------+----+--------------------+----+-----+----+---+----------+-----+------------+---+\n",
      "\n",
      "Total records:  17"
     ]
    }
   ],
   "source": [
    "full_data = glueContext.create_dynamic_frame.from_catalog(database = \"devtest\", table_name = \"ymd_partitioned_data\",\n",
    "                                                                    transformation_ctx = \"datasource_catalog\")\n",
    "exact_date_data = Filter.apply(frame = full_data, f = lambda x: x[\"reading_date\"] in ['2019-05-29'])\n",
    "exact_date_data.toDF().show()\n",
    "print('Total records: ', exact_date_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T00:45:22.271850Z",
     "start_time": "2021-08-31T00:45:14.844098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----+----+---+---+---+----------+--------------------+------------+\n",
      "|    bsid|dtsid|msid| msv|  t|  c|  b| file_date|          reading_dt|reading_date|\n",
      "+--------+-----+----+----+---+---+---+----------+--------------------+------------+\n",
      "|90020195|   24| 962|  25|  0|  0|  1|2019-06-03|2019-05-29 19:45:...|  2019-05-29|\n",
      "|90020195|   16| 674|2800|  0|  0|  0|2019-06-03|2019-05-29 12:25:...|  2019-05-29|\n",
      "|90020195|   17| 705|1070|  0|  0|  0|2019-06-02|2019-05-29 16:45:...|  2019-05-29|\n",
      "|90020195|   17| 705|1070|  0|  0|  0|2019-06-01|2019-05-29 16:45:...|  2019-05-29|\n",
      "|90020195|   17| 705|1070|  0|  0|  0|2019-06-04|2019-05-29 16:45:...|  2019-05-29|\n",
      "|90020195|   24| 962|  25|  0|  0|  1|2019-06-04|2019-05-29 19:45:...|  2019-05-29|\n",
      "|90020195|   17| 705|1070|  0|  0|  0|2019-06-03|2019-05-29 16:45:...|  2019-05-29|\n",
      "|90020195|   16| 674|2800|  0|  0|  0|2019-06-04|2019-05-29 12:25:...|  2019-05-29|\n",
      "|90020195|    3| 168|4113|  0|  0|  0|2019-06-04|2019-05-29 04:01:...|  2019-05-29|\n",
      "|90020195|    3| 168|4113|  0|  0|  0|2019-06-02|2019-05-29 04:01:...|  2019-05-29|\n",
      "|90020195|    3| 168|4113|  0|  0|  0|2019-06-01|2019-05-29 04:01:...|  2019-05-29|\n",
      "|90020195|   16| 674|2800|  0|  0|  0|2019-06-02|2019-05-29 12:25:...|  2019-05-29|\n",
      "|90020195|   24| 962|  25|  0|  0|  1|2019-06-01|2019-05-29 19:45:...|  2019-05-29|\n",
      "|90020195|    3| 168|4113|  0|  0|  0|2019-06-03|2019-05-29 04:01:...|  2019-05-29|\n",
      "|90020195|    1|   9|2057|  0|  0|  0|2019-06-01|2019-05-29 20:15:...|  2019-05-29|\n",
      "|90020195|   24| 962|  25|  0|  0|  1|2019-06-02|2019-05-29 19:45:...|  2019-05-29|\n",
      "|90020195|   16| 674|2800|  0|  0|  0|2019-06-01|2019-05-29 12:25:...|  2019-05-29|\n",
      "+--------+-----+----+----+---+---+---+----------+--------------------+------------+\n",
      "\n",
      "Total records:  17"
     ]
    }
   ],
   "source": [
    "exact_date_data = glueContext.create_dynamic_frame.from_catalog(database = \"devtest\", table_name = \"date_partitioned_data\",\n",
    "                                                                push_down_predicate = \"(reading_date == '2019-05-29')\", transformation_ctx = \"datasource_catalog\")\n",
    "exact_date_data.toDF().show()\n",
    "print('Total records: ', exact_date_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T00:45:11.967941Z",
     "start_time": "2021-08-31T00:45:04.372238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----+----+---+---+---+----------+--------------------+------------+----+-----+---+\n",
      "|    bsid|dtsid|msid| msv|  t|  c|  b| file_date|          reading_dt|reading_date|year|month|day|\n",
      "+--------+-----+----+----+---+---+---+----------+--------------------+------------+----+-----+---+\n",
      "|90020195|   16| 674|2800|  0|  0|  0|2019-06-01|2019-05-29 12:25:...|  2019-05-29|2019|    5| 29|\n",
      "|90020195|   24| 962|  25|  0|  0|  1|2019-06-01|2019-05-29 19:45:...|  2019-05-29|2019|    5| 29|\n",
      "|90020195|    3| 168|4113|  0|  0|  0|2019-06-03|2019-05-29 04:01:...|  2019-05-29|2019|    5| 29|\n",
      "|90020195|   24| 962|  25|  0|  0|  1|2019-06-02|2019-05-29 19:45:...|  2019-05-29|2019|    5| 29|\n",
      "|90020195|   17| 705|1070|  0|  0|  0|2019-06-03|2019-05-29 16:45:...|  2019-05-29|2019|    5| 29|\n",
      "|90020195|    3| 168|4113|  0|  0|  0|2019-06-01|2019-05-29 04:01:...|  2019-05-29|2019|    5| 29|\n",
      "|90020195|   24| 962|  25|  0|  0|  1|2019-06-04|2019-05-29 19:45:...|  2019-05-29|2019|    5| 29|\n",
      "|90020195|   17| 705|1070|  0|  0|  0|2019-06-04|2019-05-29 16:45:...|  2019-05-29|2019|    5| 29|\n",
      "|90020195|    3| 168|4113|  0|  0|  0|2019-06-04|2019-05-29 04:01:...|  2019-05-29|2019|    5| 29|\n",
      "|90020195|   16| 674|2800|  0|  0|  0|2019-06-03|2019-05-29 12:25:...|  2019-05-29|2019|    5| 29|\n",
      "|90020195|    3| 168|4113|  0|  0|  0|2019-06-02|2019-05-29 04:01:...|  2019-05-29|2019|    5| 29|\n",
      "|90020195|   16| 674|2800|  0|  0|  0|2019-06-02|2019-05-29 12:25:...|  2019-05-29|2019|    5| 29|\n",
      "|90020195|   17| 705|1070|  0|  0|  0|2019-06-01|2019-05-29 16:45:...|  2019-05-29|2019|    5| 29|\n",
      "|90020195|    1|   9|2057|  0|  0|  0|2019-06-01|2019-05-29 20:15:...|  2019-05-29|2019|    5| 29|\n",
      "|90020195|   16| 674|2800|  0|  0|  0|2019-06-04|2019-05-29 12:25:...|  2019-05-29|2019|    5| 29|\n",
      "|90020195|   24| 962|  25|  0|  0|  1|2019-06-03|2019-05-29 19:45:...|  2019-05-29|2019|    5| 29|\n",
      "|90020195|   17| 705|1070|  0|  0|  0|2019-06-02|2019-05-29 16:45:...|  2019-05-29|2019|    5| 29|\n",
      "+--------+-----+----+----+---+---+---+----------+--------------------+------------+----+-----+---+\n",
      "\n",
      "Total records:  17"
     ]
    }
   ],
   "source": [
    "exact_date_data = glueContext.create_dynamic_frame.from_catalog(database = \"devtest\", table_name = \"ymd_partitioned_data\",\n",
    "                                                                push_down_predicate = \"(year == '2019'and month == '5'and day == '29')\", transformation_ctx = \"datasource_catalog\")\n",
    "exact_date_data.toDF().show()\n",
    "print('Total records: ', exact_date_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "1. Without using \"push_down_predicate\" but filter the date with DynamicFrame native functions (5m55s)\n",
    "2. Using \"push_down_predicate\" to filter the data returned from Glue (7.43s)\n",
    "3. Using \"push_down_predicate\" on a year/month/day-parttioned data set (7.59s)\n",
    "\n",
    "For this particular data set, using an exact date is slightly faster\n",
    "\n",
    "The general conclusion is, if there are a lot more dates presented, the performance enhancement of getting data from a time range / specific date would be more efficient by year/month/day approach, whereas in scenario where the distinct dates are relatively small, using the date itself as a partition key may help in reducing the number of partitions created and hence may produce faster results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
